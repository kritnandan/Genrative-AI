
In this project, I delved into the realm of Generative AI, where I successfully implemented the Large Language Model (LLM) and Transformer. The project involved encoding and decoding mechanisms, along with the incorporation of a softmax function. Through this endeavor, we were able to effectively extract answers to questions posed within the dataset.

Moreover, the model demonstrated its versatility by facilitating language translation, seamlessly converting text from one language to another. This project not only honed my understanding of Generative AI but also showcased the practical application of LLM, transformer architecture, and associated functions in solving real-world problems.

The Dataset consist of a patients current weight, weight loss, alcohal assumptions, smoking status, medication etc so whenever I ask questions regarding this from the model then on the basis of encoder and decoder give the answer of that particular question. 



**Used Method for the Project**
 1. Tonkenization
 2. Data Preprocessing 
 3. Encoding
 4. Decoding
 5. Transformer
    

**link for deep learning** 

      ```bash
    https://www.mathworks.com/discovery/deep-learning.html
    https://medium.com/intro-to-artificial-intelligence/deep-learning-series-1-intro-to-deep-learning-abb1780ee20

**link for an introduction to generative ai**

  ```bash
    https://www.youtube.com/watch?v=G2fqAlgmoPo
    https://www.cloudskillsboost.google/paths/118/course_templates/536
    https://www.cloudskillsboost.google/paths/118/course_templates/539
    https://www.cloudskillsboost.google/paths/118/course_templates/556
    
**link for the transformer** 

      ```bash
    https://arxiv.org/pdf/1706.03762.pdf
    https://jalammar.github.io/illustrated-transformer/
    
**link for the assignment** 

      ```bash
    https://docs.google.com/document/d/1qGwkITbUvRjcbIHl0tNmBzYvOkT-5FCH5gdTUROxO74/edit
